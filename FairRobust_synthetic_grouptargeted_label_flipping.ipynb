{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair and Robust Sample Selection on the Synthetic Dataset\n",
    "## With Group-Targeted Label Flipping\n",
    "\n",
    "#### This Jupyter Notebook simulates the proposed fair and robust sample selection on the synthetic data.\n",
    "#### We use two fairness metrics: equalized odds and demographic parity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch\n",
    "\n",
    "from models import LogisticRegression, weights_init_normal, test_model\n",
    "from FairRobustSampler import FairRobust, CustomDataset\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and process the data\n",
    "In the synthetic_data directory, there are a total of 11 numpy files including training data (both clean and noisy), validation data, and test data. Note that the validation data is utilized for another method in the paper (i.e., FR-Train), so the data is not used in this program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xz_train = np.load('./synthetic_data/xz_train.npy')\n",
    "y_train = np.load('./synthetic_data/y_train.npy')\n",
    "z_train = np.load('./synthetic_data/z_train.npy')\n",
    "\n",
    "y_noise = np.load('./synthetic_data/y_noise_grouptarget.npy') # Labels with the group-targeted label flipping (details are in the paper)\n",
    "poi_ratio = 0.1\n",
    "\n",
    "xz_test = np.load('./synthetic_data/xz_test.npy')\n",
    "y_test = np.load('./synthetic_data/y_test.npy') \n",
    "z_test = np.load('./synthetic_data/z_test.npy')\n",
    "\n",
    "xz_train = torch.FloatTensor(xz_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "z_train = torch.FloatTensor(z_train)\n",
    "\n",
    "y_noise = torch.FloatTensor(y_noise)\n",
    "\n",
    "xz_test = torch.FloatTensor(xz_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "z_test = torch.FloatTensor(z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    xz_train = xz_train.cuda()\n",
    "    y_noise = y_noise.cuda()\n",
    "    y_train = y_train.cuda()\n",
    "    z_train = z_train.cuda()\n",
    "    \n",
    "    xz_test = xz_test.cuda()\n",
    "    y_test = y_test.cuda()\n",
    "    z_test = z_test.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Number of Data ----------\n",
      "Train data : 2000, Test data : 1000 \n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------- Number of Data ----------\" )\n",
    "print(\n",
    "    \"Train data : %d, Test data : %d \"\n",
    "    % (len(y_train), len(y_test))\n",
    ")       \n",
    "print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, train_features, labels, optimizer, criterion):\n",
    "    \"\"\"Trains the model with the given train data.\n",
    "\n",
    "    Args:\n",
    "        model: A torch model to train.\n",
    "        train_features: A torch tensor indicating the train features.\n",
    "        labels: A torch tensor indicating the true labels.\n",
    "        optimizer: A torch optimizer.\n",
    "        criterion: A torch criterion.\n",
    "\n",
    "    Returns:\n",
    "        loss values.\n",
    "    \"\"\"\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    label_predicted = model.forward(train_features)\n",
    "    loss  = criterion((F.tanh(label_predicted.squeeze())+1)/2, (labels.squeeze()+1)/2)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fair and Robust Sample Selection w.r.t. Equalized Odds\n",
    "### The results are in the experiments of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Seed: 0 >\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9288/1264777586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# ---------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mcuda\u001b[1;34m(self, device)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mModule\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \"\"\"\n\u001b[1;32m--> 680\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mxpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    206\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "full_tests = []\n",
    "\n",
    "parameters = Namespace(warm_start=100, tau=1-poi_ratio, alpha = 0.001, batch_size = 100)\n",
    "\n",
    "# Set the train data\n",
    "train_data = CustomDataset(xz_train, y_noise, z_train)\n",
    "\n",
    "seeds = [0,1,2,3,4]\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    print(\"< Seed: {} >\".format(seed))\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Initialize model, optimizer, and criterion\n",
    "    # ---------------------\n",
    "    \n",
    "   #  model = LogisticRegression(3,1).cuda()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Define FairRobust and DataLoader\n",
    "    # ---------------------\n",
    "\n",
    "    sampler = FairRobust (model, train_data.x, train_data.y, train_data.z, target_fairness = 'eqodds', parameters = parameters, replacement = False, seed = seed)\n",
    "    train_loader = torch.utils.data.DataLoader (train_data, sampler=sampler, num_workers=0)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Model training\n",
    "    # ---------------------\n",
    "    for epoch in range(450):\n",
    "        print(epoch, end=\"\\r\")\n",
    "        \n",
    "        tmp_loss = []\n",
    "        \n",
    "        for batch_idx, (data, target, z) in enumerate (train_loader):\n",
    "            loss = run_epoch (model, data, target, optimizer, criterion)\n",
    "            tmp_loss.append(loss)\n",
    "            \n",
    "        losses.append(sum(tmp_loss)/len(tmp_loss))\n",
    "        \n",
    "\n",
    "    tmp_test = test_model(model, xz_test, y_test, z_test)\n",
    "    full_tests.append(tmp_test)\n",
    "    \n",
    "    print(\"  Test accuracy: {}, EO disparity: {}\".format(tmp_test['Acc'], tmp_test['EqOdds_diff']))\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (avg): 0.7260000228881835\n",
      "EO disparity  (avg): 0.040289772577944014\n"
     ]
    }
   ],
   "source": [
    "tmp_acc = []\n",
    "tmp_eo = []\n",
    "for i in range(len(seeds)):\n",
    "    tmp_acc.append(full_tests[i]['Acc'])\n",
    "    tmp_eo.append(full_tests[i]['EqOdds_diff'])\n",
    "\n",
    "print(\"Test accuracy (avg): {}\".format(sum(tmp_acc)/len(tmp_acc)))\n",
    "print(\"EO disparity  (avg): {}\".format(sum(tmp_eo)/len(tmp_eo)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fair and Robust Sample Selection w.r.t. Demographic Parity\n",
    "### The results are in the experiments of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Seed: 0 >\n",
      "  Test accuracy: 0.7220000624656677, DP disparity: 0.020555555555555605\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 1 >\n",
      "  Test accuracy: 0.7210000157356262, DP disparity: 0.03270707070707074\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 2 >\n",
      "  Test accuracy: 0.718000054359436, DP disparity: 0.05906060606060609\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 3 >\n",
      "  Test accuracy: 0.718000054359436, DP disparity: 0.042858585858585874\n",
      "----------------------------------------------------------------------\n",
      "< Seed: 4 >\n",
      "  Test accuracy: 0.7200000286102295, DP disparity: 0.03980808080808085\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "full_tests = []\n",
    "\n",
    "parameters = Namespace(warm_start=100, tau=1-poi_ratio, alpha = 0.001, batch_size = 100)\n",
    "\n",
    "# Set the train data\n",
    "train_data = CustomDataset(xz_train, y_noise, z_train)\n",
    "\n",
    "seeds = [0,1,2,3,4]\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    print(\"< Seed: {} >\".format(seed))\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Initialize model, optimizer, and criterion\n",
    "    # ---------------------\n",
    "    \n",
    "    model = LogisticRegression(3,1).cuda()\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    model.apply(weights_init_normal)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, betas=(0.9, 0.999))\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses = []\n",
    "    \n",
    "    # ---------------------\n",
    "    #  Define FairRobust and DataLoader\n",
    "    # ---------------------\n",
    "\n",
    "    sampler = FairRobust (model, train_data.x, train_data.y, train_data.z, target_fairness = 'dp', parameters = parameters, replacement = False, seed = seed)\n",
    "    train_loader = torch.utils.data.DataLoader (train_data, sampler=sampler, num_workers=0)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Model training\n",
    "    # ---------------------\n",
    "    for epoch in range(500):\n",
    "        print(epoch, end=\"\\r\")\n",
    "        \n",
    "        tmp_loss = []\n",
    "        \n",
    "        for batch_idx, (data, target, z) in enumerate (train_loader):\n",
    "            loss = run_epoch (model, data, target, optimizer, criterion)\n",
    "            tmp_loss.append(loss)\n",
    "            \n",
    "        losses.append(sum(tmp_loss)/len(tmp_loss))\n",
    "        \n",
    "    tmp_test = test_model(model, xz_test, y_test, z_test)\n",
    "    full_tests.append(tmp_test)\n",
    "    \n",
    "    print(\"  Test accuracy: {}, DP disparity: {}\".format(tmp_test['Acc'], tmp_test['DP_diff']))\n",
    "    print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy (avg): 0.7198000431060791\n",
      "DP disparity  (avg): 0.03899797979797983\n"
     ]
    }
   ],
   "source": [
    "tmp_acc = []\n",
    "tmp_dp = []\n",
    "for i in range(len(seeds)):\n",
    "    tmp_acc.append(full_tests[i]['Acc'])\n",
    "    tmp_dp.append(full_tests[i]['DP_diff'])\n",
    "\n",
    "print(\"Test accuracy (avg): {}\".format(sum(tmp_acc)/len(tmp_acc)))\n",
    "print(\"DP disparity  (avg): {}\".format(sum(tmp_dp)/len(tmp_dp)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
